{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, kernel_initializer='random_uniform'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              # List of metrics to monitor\n",
    "              metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.6975 - sparse_categorical_accuracy: 0.8477 - val_loss: 1.5828 - val_sparse_categorical_accuracy: 0.9065\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 1.5831 - sparse_categorical_accuracy: 0.9039 - val_loss: 1.5614 - val_sparse_categorical_accuracy: 0.9176\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5670 - sparse_categorical_accuracy: 0.9127 - val_loss: 1.5545 - val_sparse_categorical_accuracy: 0.9199\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5592 - sparse_categorical_accuracy: 0.9166 - val_loss: 1.5495 - val_sparse_categorical_accuracy: 0.9239\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.5544 - sparse_categorical_accuracy: 0.9195 - val_loss: 1.5461 - val_sparse_categorical_accuracy: 0.9240\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5507 - sparse_categorical_accuracy: 0.9213 - val_loss: 1.5437 - val_sparse_categorical_accuracy: 0.9261\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5481 - sparse_categorical_accuracy: 0.9236 - val_loss: 1.5422 - val_sparse_categorical_accuracy: 0.9258\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5460 - sparse_categorical_accuracy: 0.9247 - val_loss: 1.5410 - val_sparse_categorical_accuracy: 0.9276\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5442 - sparse_categorical_accuracy: 0.9257 - val_loss: 1.5394 - val_sparse_categorical_accuracy: 0.9285\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5426 - sparse_categorical_accuracy: 0.9273 - val_loss: 1.5386 - val_sparse_categorical_accuracy: 0.9295\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5415 - sparse_categorical_accuracy: 0.9280 - val_loss: 1.5378 - val_sparse_categorical_accuracy: 0.9289\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5402 - sparse_categorical_accuracy: 0.9290 - val_loss: 1.5370 - val_sparse_categorical_accuracy: 0.9303\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5392 - sparse_categorical_accuracy: 0.9298 - val_loss: 1.5360 - val_sparse_categorical_accuracy: 0.9312\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5384 - sparse_categorical_accuracy: 0.9301 - val_loss: 1.5357 - val_sparse_categorical_accuracy: 0.9311\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5375 - sparse_categorical_accuracy: 0.9309 - val_loss: 1.5350 - val_sparse_categorical_accuracy: 0.9320\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5367 - sparse_categorical_accuracy: 0.9309 - val_loss: 1.5347 - val_sparse_categorical_accuracy: 0.9324\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5360 - sparse_categorical_accuracy: 0.9318 - val_loss: 1.5340 - val_sparse_categorical_accuracy: 0.9327\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5355 - sparse_categorical_accuracy: 0.9320 - val_loss: 1.5339 - val_sparse_categorical_accuracy: 0.9317\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5348 - sparse_categorical_accuracy: 0.9326 - val_loss: 1.5328 - val_sparse_categorical_accuracy: 0.9337\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5343 - sparse_categorical_accuracy: 0.9330 - val_loss: 1.5326 - val_sparse_categorical_accuracy: 0.9335\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5338 - sparse_categorical_accuracy: 0.9333 - val_loss: 1.5324 - val_sparse_categorical_accuracy: 0.9336\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5333 - sparse_categorical_accuracy: 0.9338 - val_loss: 1.5323 - val_sparse_categorical_accuracy: 0.9338\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5328 - sparse_categorical_accuracy: 0.9344 - val_loss: 1.5320 - val_sparse_categorical_accuracy: 0.9336\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5323 - sparse_categorical_accuracy: 0.9348 - val_loss: 1.5320 - val_sparse_categorical_accuracy: 0.9328\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5320 - sparse_categorical_accuracy: 0.9352 - val_loss: 1.5318 - val_sparse_categorical_accuracy: 0.9335\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5315 - sparse_categorical_accuracy: 0.9352 - val_loss: 1.5310 - val_sparse_categorical_accuracy: 0.9348\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5313 - sparse_categorical_accuracy: 0.9353 - val_loss: 1.5314 - val_sparse_categorical_accuracy: 0.9343\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5308 - sparse_categorical_accuracy: 0.9358 - val_loss: 1.5308 - val_sparse_categorical_accuracy: 0.9341\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5305 - sparse_categorical_accuracy: 0.9358 - val_loss: 1.5304 - val_sparse_categorical_accuracy: 0.9347\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5303 - sparse_categorical_accuracy: 0.9364 - val_loss: 1.5305 - val_sparse_categorical_accuracy: 0.9351\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5299 - sparse_categorical_accuracy: 0.9367 - val_loss: 1.5301 - val_sparse_categorical_accuracy: 0.9348\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5296 - sparse_categorical_accuracy: 0.9363 - val_loss: 1.5300 - val_sparse_categorical_accuracy: 0.9353\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5294 - sparse_categorical_accuracy: 0.9366 - val_loss: 1.5300 - val_sparse_categorical_accuracy: 0.9342\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5290 - sparse_categorical_accuracy: 0.9372 - val_loss: 1.5296 - val_sparse_categorical_accuracy: 0.9352\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5288 - sparse_categorical_accuracy: 0.9374 - val_loss: 1.5295 - val_sparse_categorical_accuracy: 0.9352\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5286 - sparse_categorical_accuracy: 0.9372 - val_loss: 1.5296 - val_sparse_categorical_accuracy: 0.9343\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5283 - sparse_categorical_accuracy: 0.9375 - val_loss: 1.5294 - val_sparse_categorical_accuracy: 0.9346\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5280 - sparse_categorical_accuracy: 0.9378 - val_loss: 1.5292 - val_sparse_categorical_accuracy: 0.9359\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5279 - sparse_categorical_accuracy: 0.9376 - val_loss: 1.5292 - val_sparse_categorical_accuracy: 0.9366\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5277 - sparse_categorical_accuracy: 0.9380 - val_loss: 1.5290 - val_sparse_categorical_accuracy: 0.9353\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5274 - sparse_categorical_accuracy: 0.9382 - val_loss: 1.5292 - val_sparse_categorical_accuracy: 0.9358\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5272 - sparse_categorical_accuracy: 0.9384 - val_loss: 1.5288 - val_sparse_categorical_accuracy: 0.9365\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5270 - sparse_categorical_accuracy: 0.9388 - val_loss: 1.5289 - val_sparse_categorical_accuracy: 0.9352\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5267 - sparse_categorical_accuracy: 0.9394 - val_loss: 1.5286 - val_sparse_categorical_accuracy: 0.9361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5266 - sparse_categorical_accuracy: 0.9388 - val_loss: 1.5285 - val_sparse_categorical_accuracy: 0.9360\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5264 - sparse_categorical_accuracy: 0.9391 - val_loss: 1.5286 - val_sparse_categorical_accuracy: 0.9357\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5262 - sparse_categorical_accuracy: 0.9393 - val_loss: 1.5286 - val_sparse_categorical_accuracy: 0.9353\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5259 - sparse_categorical_accuracy: 0.9398 - val_loss: 1.5283 - val_sparse_categorical_accuracy: 0.9363\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 1.5258 - sparse_categorical_accuracy: 0.9399 - val_loss: 1.5282 - val_sparse_categorical_accuracy: 0.9360\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.5257 - sparse_categorical_accuracy: 0.9398 - val_loss: 1.5284 - val_sparse_categorical_accuracy: 0.9367\n",
      "\n",
      "history dict: {'val_loss': [1.5828031702041625, 1.561392614555359, 1.5544602197647095, 1.5494720762252807, 1.5461036796569825, 1.5437317279815674, 1.542189170074463, 1.5409898120880128, 1.5393976692199707, 1.538591262435913, 1.5377557552337646, 1.537003040122986, 1.535962773513794, 1.5357186101913451, 1.535025033378601, 1.5346524974822997, 1.5340334678649903, 1.5339273830413818, 1.532784203338623, 1.5326328311920165, 1.5324109325408934, 1.5322595142364501, 1.5320166719436645, 1.5319750747680665, 1.5318124816894532, 1.5309802923202516, 1.5313754852294923, 1.5307788333892822, 1.5304075115203857, 1.5305392026901246, 1.5301228261947633, 1.5299567951202393, 1.5300310319900512, 1.5295552589416503, 1.5294995555877686, 1.5296379428863525, 1.5294196510314941, 1.5291743856430053, 1.5291908004760741, 1.5290486106872558, 1.5292398267745972, 1.5287889726638795, 1.5288895988464355, 1.5286443048477172, 1.5284506675720215, 1.5285730049133301, 1.5285647375106812, 1.5282669822692871, 1.52823616065979, 1.5283564155578613], 'val_sparse_categorical_accuracy': [0.906499981880188, 0.9175999760627747, 0.9199000000953674, 0.9239000082015991, 0.9240000247955322, 0.9261000156402588, 0.9258000254631042, 0.9276000261306763, 0.9284999966621399, 0.9294999837875366, 0.9289000034332275, 0.9302999973297119, 0.9312000274658203, 0.9311000108718872, 0.9319999814033508, 0.9323999881744385, 0.932699978351593, 0.9316999912261963, 0.9337000250816345, 0.9334999918937683, 0.9336000084877014, 0.9337999820709229, 0.9336000084877014, 0.9327999949455261, 0.9334999918937683, 0.9348000288009644, 0.9343000054359436, 0.9340999722480774, 0.9347000122070312, 0.9351000189781189, 0.9348000288009644, 0.9352999925613403, 0.9341999888420105, 0.9351999759674072, 0.9351999759674072, 0.9343000054359436, 0.9345999956130981, 0.9358999729156494, 0.9366000294685364, 0.9352999925613403, 0.9358000159263611, 0.9365000128746033, 0.9351999759674072, 0.9361000061035156, 0.9359999895095825, 0.935699999332428, 0.9352999925613403, 0.9362999796867371, 0.9359999895095825, 0.9366999864578247], 'loss': [1.697490658340454, 1.5831119425964355, 1.5669932041931152, 1.5592163124847411, 1.554414126663208, 1.5506599604797364, 1.5481341606140138, 1.5459968920898437, 1.5442012945175172, 1.5426262361907959, 1.5414868563842774, 1.5401678045272826, 1.5391637866592407, 1.53836286819458, 1.537487559967041, 1.5366967055511476, 1.5360279634094238, 1.535480383491516, 1.5348054774475097, 1.534289002685547, 1.5337731578826905, 1.5332815399932862, 1.5328094413375855, 1.5323214218521117, 1.5320126371765137, 1.5314825859069825, 1.5312942681121826, 1.5308254264068604, 1.5305392918777465, 1.5302730628204346, 1.5299103749847411, 1.5296374904632568, 1.5294192929458619, 1.5290472424697876, 1.5287963436126708, 1.5285709727478027, 1.5283242110443116, 1.528020467224121, 1.5279000383758545, 1.5276792943572999, 1.5273985068511964, 1.527203812828064, 1.5269737216949464, 1.5267410878372192, 1.526570965156555, 1.526403445892334, 1.5262187357330321, 1.5258727496337892, 1.525807675743103, 1.5256542706298828], 'sparse_categorical_accuracy': [0.84766, 0.90392, 0.9127, 0.91664, 0.9195, 0.92134, 0.92364, 0.92474, 0.92574, 0.92726, 0.92798, 0.929, 0.92982, 0.93006, 0.9309, 0.9309, 0.93176, 0.932, 0.93262, 0.93302, 0.93326, 0.93384, 0.93436, 0.93484, 0.93518, 0.9352, 0.93532, 0.93584, 0.9358, 0.93642, 0.9367, 0.93626, 0.9366, 0.9372, 0.93742, 0.93722, 0.9375, 0.93776, 0.93764, 0.938, 0.93824, 0.93838, 0.9388, 0.93938, 0.93878, 0.93914, 0.93932, 0.93984, 0.93994, 0.9398]}\n"
     ]
    }
   ],
   "source": [
    "print('# Fit model on training data')\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=50,\n",
    "                    # We pass some validation for\n",
    "                    # monitoring validation loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "print('\\nhistory dict:', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate on test data\n",
      "10000/10000 [==============================] - 0s 7us/step\n",
      "test loss, test acc: [1.5314489702224732, 0.9336000084877014]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Generate predictions for 3 samples\n",
      "predictions shape: [2]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "predictions = model.predict_classes(x_test[1].reshape(-1,784))\n",
    "print('predictions shape:', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
